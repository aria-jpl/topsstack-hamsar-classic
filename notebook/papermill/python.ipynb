{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "recreational-madison",
   "metadata": {},
   "source": [
    "# TOPS Stack Notebook\n",
    "\n",
    "## Introduction\n",
    "In this notebook, we will run all steps of processing Tops Stack. \n",
    "The detailed algorithm for stack processing of TOPS data can be find here:\n",
    "\n",
    "+ Fattahi, H., P. Agram, and M. Simons (2016), A Network-Based Enhanced Spectral Diversity Approach for TOPS Time-Series Analysis, IEEE Transactions on Geoscience and Remote Sensing, 55(2), 777-786, doi:[10.1109/TGRS.2016.2614925](https://ieeexplore.ieee.org/abstract/document/7637021).\n",
    "\n",
    "-----------------------------------\n",
    "\n",
    "#### Note\n",
    "Be sure to have ~/.netrc file include valid credentials for urs.earthdata.nasa.gov.\n",
    "\n",
    "This notebook can process TOPS stacks for given spatial and temporal constraints.\n",
    "\n",
    "**Input Parameters**\n",
    "\n",
    "- **lat_min, lat_max, lon_min, lon_max**: min/max latitude and longitude of Region of Interest.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "matched-child",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.57793709766442 36.21619047354823 -84.70058767311058 -83.94773267597341\n"
     ]
    }
   ],
   "source": [
    "lat_min = 35.57793709766442\n",
    "lat_max = 36.21619047354823\n",
    "lon_min = -84.70058767311058\n",
    "lon_max = -83.94773267597341\n",
    "\n",
    "print(lat_min, lat_max, lon_min, lon_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "transsexual-report",
   "metadata": {},
   "source": [
    "## Initialization and set up\n",
    "\n",
    "You might have to modify 00-init.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "internal-standard",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coords:\n",
      "34.285041 37.501509 -86.721161 -83.227722 34 38 -87 -83\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "toolDir=~/tops-stack-processor-hamsar-develop-conda-isce2/topsstack-hamsar\n",
    "\n",
    "source ${toolDir}/00-init.sh\n",
    "source ${toolDir}/01-setup.sh\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deluxe-grocery",
   "metadata": {},
   "source": [
    "\n",
    "topsStack requires certain input to run which are SLCs, Orbits, Dems etc.\n",
    "\n",
    "## Fetch DEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protecting-cable",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "toolDir=~/tops-stack-processor-hamsar-develop-conda-isce2/topsstack-hamsar\n",
    "\n",
    "source ${toolDir}/00-init.sh\n",
    "source ${toolDir}/01-setup.sh\n",
    "\n",
    "sh ${toolDir}/03-get-dems.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compound-penny",
   "metadata": {},
   "source": [
    "## Create run scripts and fetch orbits\n",
    "\n",
    "The scripts provides support for Sentinel-1 TOPS stack processing. Currently supported workflows include a coregistered stack of SLC, interferograms, offsets, and coherence. \n",
    "\n",
    "`stackSentinel.py` generates all configuration and run files required to be executed on a stack of Sentinel-1 TOPS data. When stackSentinel.py is executed for a given workflow (-W option) a **configs** and **run_files** folder is generated. No processing is performed at this stage. Within the run_files folder different run\\_#\\_description files are contained which are to be executed as shell scripts in the run number order. Each of these run scripts call specific configure files contained in the “configs” folder which call ISCE in a modular fashion. The configure and run files will change depending on the selected workflow. To make run_# files executable, change the file permission accordingly (e.g., `chmod +x run_01_unpack_slc`).\n",
    "\n",
    "```bash\n",
    "stackSentinel.py -H     #To see workflow examples,\n",
    "stackSentinel.py -h     #To get an overview of all the configurable parameters\n",
    "```\n",
    "\n",
    "Required parameters of stackSentinel.py include:\n",
    "\n",
    "```cfg\n",
    "-s SLC_DIRNAME          #A folder with downloaded Sentinel-1 SLC’s. \n",
    "-o ORBIT_DIRNAME        #A folder containing the Sentinel-1 orbits. Missing orbit files will be downloaded automatically\n",
    "-a AUX_DIRNAME          #A folder containing the Sentinel-1 Auxiliary files\n",
    "-d DEM_FILENAME         #A DEM (Digital Elevation Model) referenced to wgs84\n",
    "```\n",
    "\n",
    "In the following, different workflow examples are provided. Note that stackSentinel.py only generates the run and configure files. To perform the actual processing, the user will need to execute each run file in their numbered order.\n",
    "\n",
    "In all workflows, coregistration (-C option) can be done using only geometry (set option = geometry) or with geometry plus refined azimuth offsets through NESD (set option = NESD) approach, the latter being the default. For the NESD coregistrstion the user can control the ESD coherence threshold (-e option) and the number of overlap interferograms (-O) to be used in NESD estimation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "congressional-orchestra",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "toolDir=~/tops-stack-processor-hamsar-develop-conda-isce2/topsstack-hamsar\n",
    "\n",
    "source ${toolDir}/00-init.sh\n",
    "source ${toolDir}/01-setup.sh\n",
    "\n",
    "sh ${toolDir}/04-make-run-scripts.sh\n",
    "sh ${toolDir}/05-make-run-scripts.sh\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opponent-telling",
   "metadata": {},
   "source": [
    "## Unpack TOPO reference\n",
    "\n",
    "Unpacks the reference SLC files using ISCE readers, also unpackaging the antenna elevation pattern correction file if necessary. This run file also produces the reference geometry files that are consumed downstream.\n",
    "\n",
    "Includes commands to unpack Sentinel-1 TOPS SLCs using ISCE readers. For older SLCs which need antenna elevation pattern correction, the file is extracted and written to disk. For newer version of SLCs which don’t need the elevation antenna pattern correction, only a gdal virtual “vrt” file (and isce xml file) is generated. The “.vrt” file points to the Sentinel SLC file and reads them whenever required during the processing. If a user wants to write the “.vrt” SLC file to disk, it can be done easily using gdal_translate (e.g. gdal_translate –of ENVI File.vrt File.slc). \n",
    "The “run_01_unpack_slc_topo_reference” also includes a command that refers to the config file of the stack reference, which includes configuration for running topo for the stack reference. Note that in the pair-wise processing strategy one should run topo (mapping from range-Doppler to geo coordinate) for all pairs. However, with stackSentinel, topo needs to be run only one time for the reference in the stack. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acknowledged-nightmare",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "toolDir=~/tops-stack-processor-hamsar-develop-conda-isce2/topsstack-hamsar\n",
    "\n",
    "source ${toolDir}/00-init.sh\n",
    "source ${toolDir}/01-setup.sh\n",
    "\n",
    "sh ${toolDir}/06-run-01.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "authorized-desert",
   "metadata": {},
   "source": [
    "## Unpack secondary SLC\n",
    "\n",
    "Unpack Secondary SLCs\n",
    "In a manner similar to the SLCs in the step above, this step unpacks the secondary SLCs from each of the input SLC zip files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "returning-superintendent",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "toolDir=~/tops-stack-processor-hamsar-develop-conda-isce2/topsstack-hamsar\n",
    "\n",
    "source ${toolDir}/00-init.sh\n",
    "source ${toolDir}/01-setup.sh\n",
    "\n",
    "sh ${toolDir}/06-run-02-0.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "micro-zealand",
   "metadata": {},
   "source": [
    "## SLC noise calibration\n",
    "\n",
    "This step runs radiometric and thermal noise calibration using vh-pol data against the SLCs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "domestic-finland",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "toolDir=~/tops-stack-processor-hamsar-develop-conda-isce2/topsstack-hamsar\n",
    "\n",
    "source ${toolDir}/00-init.sh\n",
    "source ${toolDir}/01-setup.sh\n",
    "\n",
    "sh ${toolDir}/06-run-02-5.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nearby-congress",
   "metadata": {},
   "source": [
    "## Discard subswaths not to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sitting-revolution",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "toolDir=~/tops-stack-processor-hamsar-develop-conda-isce2/topsstack-hamsar\n",
    "\n",
    "source ${toolDir}/00-init.sh\n",
    "source ${toolDir}/01-setup.sh\n",
    "\n",
    "sh ${toolDir}/06-run-02-9.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worldwide-exchange",
   "metadata": {},
   "source": [
    "## Average baseline\n",
    "\n",
    "Computes average baseline for the stack. These baselines are not used for processing anywhere. They are only an approximation and can be used for plotting purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amazing-prediction",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "toolDir=~/tops-stack-processor-hamsar-develop-conda-isce2/topsstack-hamsar\n",
    "\n",
    "source ${toolDir}/00-init.sh\n",
    "source ${toolDir}/01-setup.sh\n",
    "\n",
    "sh ${toolDir}/06-run-03.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "likely-madagascar",
   "metadata": {},
   "source": [
    "## fullBurst geo2rdr\n",
    "\n",
    "This step estimates geometrical offsets between secondary burst overlaps and the stack reference burst overlaps. The secondaries are then resampled to the stack reference burst overlaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unable-baltimore",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "toolDir=~/tops-stack-processor-hamsar-develop-conda-isce2/topsstack-hamsar\n",
    "\n",
    "source ${toolDir}/00-init.sh\n",
    "source ${toolDir}/01-setup.sh\n",
    "\n",
    "sh ${toolDir}/06-run-04.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "graduate-amendment",
   "metadata": {},
   "source": [
    "## fullBurst resample\n",
    "\n",
    "Using orbit and DEM data, this run file computes geometrical offsets among all secondary SLCs and the stack reference. These offsets, with the misregistration time series are used for precise coregistration of each burst SLC.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "diverse-polish",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "toolDir=~/tops-stack-processor-hamsar-develop-conda-isce2/topsstack-hamsar\n",
    "\n",
    "source ${toolDir}/00-init.sh\n",
    "source ${toolDir}/01-setup.sh\n",
    "\n",
    "sh ${toolDir}/06-run-05.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complete-carol",
   "metadata": {},
   "source": [
    "## Extract stack valid region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "japanese-wiring",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "toolDir=~/tops-stack-processor-hamsar-develop-conda-isce2/topsstack-hamsar\n",
    "\n",
    "source ${toolDir}/00-init.sh\n",
    "source ${toolDir}/01-setup.sh\n",
    "\n",
    "sh ${toolDir}/06-run-06.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comfortable-letters",
   "metadata": {},
   "source": [
    "## Merge reference secondary SLC\n",
    "\n",
    "This step merges all bursts for the reference and coregistered SLCs. Geometry files are also merged. Using orbit and DEM, geometrical offsets among all secondary SLCs and the stack reference is computed. The geometrical offsets, together with the misregistration time-series (from previous step) are used for precise coregistration of each burst SLC. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statutory-thumb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "toolDir=~/tops-stack-processor-hamsar-develop-conda-isce2/topsstack-hamsar\n",
    "\n",
    "source ${toolDir}/00-init.sh\n",
    "source ${toolDir}/01-setup.sh\n",
    "\n",
    "sh ${toolDir}/06-run-07.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "negative-isaac",
   "metadata": {},
   "source": [
    "## Create dataset\n",
    "\n",
    "The final step ‘packages’ up the results into a single sub-directory named as coregistered_slcs-<start_date>-<end_date> and generates json files describing the dataset (e.g. the polygon  coordinates of the bounding box) and associated metadata (e.g. included SLCs).\n",
    "\n",
    "More information about metadata files can be found at : https://hysds-core.atlassian.net/wiki/spaces/HYS/pages/389349377/Product+Metadata+Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banned-flesh",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "toolDir=~/tops-stack-processor-hamsar-develop-conda-isce2/topsstack-hamsar\n",
    "\n",
    "source ${toolDir}/00-init.sh\n",
    "source ${toolDir}/01-setup.sh\n",
    "\n",
    "# fake env var PROCESSING_START for now\n",
    "export PROCESSING_START=$(date +%FT%T)\n",
    "\n",
    "sh ${toolDir}/07-make-datasets.sh"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
